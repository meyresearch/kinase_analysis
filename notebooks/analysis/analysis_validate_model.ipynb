{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from addict import Dict as Adict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mdtraj as md\n",
    "from natsort import natsorted\n",
    "\n",
    "sys.path.insert(0, '/home/rzhu/Desktop/projects/kinase_analysis/src/')\n",
    "from funcs_featurise import *\n",
    "from funcs_db_assign import *\n",
    "from funcs_indices import *\n",
    "from funcs_plotting import *\n",
    "from funcs_sample import *\n",
    "from TrajData import TrajData\n",
    "from MSMStudy import MSMStudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 14  # Font size for x-tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 14  # Font size for y-tick labels\n",
    "plt.rcParams['legend.fontsize'] = 16  # Font size for legend\n",
    "plt.rcParams['axes.labelsize'] = 18   # Font size for x-label and y-label\n",
    "plt.rcParams['axes.titlesize'] = 18   # Font size for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dataset <abl-pdb-50ps>. \n",
      "Number of raw trajectories: 749\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp_id</th>\n",
       "      <th>time_consumed</th>\n",
       "      <th>is_sparse</th>\n",
       "      <th>ev_1</th>\n",
       "      <th>ev_2</th>\n",
       "      <th>ev_3</th>\n",
       "      <th>ev_4</th>\n",
       "      <th>ev_5</th>\n",
       "      <th>ev_6</th>\n",
       "      <th>ev_7</th>\n",
       "      <th>...</th>\n",
       "      <th>vamp2_std_2</th>\n",
       "      <th>vamp2_std_3</th>\n",
       "      <th>vamp2_std_4</th>\n",
       "      <th>vamp2_std_5</th>\n",
       "      <th>vamp2_std_6</th>\n",
       "      <th>vamp2_std_7</th>\n",
       "      <th>vamp2_std_8</th>\n",
       "      <th>vamp2_std_9</th>\n",
       "      <th>vamp2_std_10</th>\n",
       "      <th>vamp2_std_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1078.257662</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>991.701226</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1000.619389</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>978.668482</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.997448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>984.544526</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>975.597075</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1073.883161</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999429</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.997496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.002876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>967.878956</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.997499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1051.143753</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.003152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>977.966633</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.997505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>966.663733</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.999732</td>\n",
       "      <td>0.999409</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.997459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>970.894698</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>941.204953</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.997515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1047.069369</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>959.351813</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.999714</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.999322</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>947.571100</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hp_id  time_consumed  is_sparse  ev_1      ev_2      ev_3      ev_4  \\\n",
       "0       1    1078.257662      False   1.0  0.999902  0.999815  0.999793   \n",
       "1       2     991.701226      False   1.0  0.999889  0.999799  0.999790   \n",
       "2       3    1000.619389      False   1.0  0.999890  0.999791  0.999772   \n",
       "3       4     978.668482      False   1.0  0.999894  0.999777  0.999766   \n",
       "4       5     984.544526      False   1.0  0.999883  0.999780  0.999753   \n",
       "5       6     975.597075      False   1.0  0.999885  0.999785  0.999748   \n",
       "6       7    1073.883161      False   1.0  0.999907  0.999773  0.999755   \n",
       "7       8     967.878956      False   1.0  0.999883  0.999763  0.999753   \n",
       "8       9    1051.143753      False   1.0  0.999904  0.999758  0.999734   \n",
       "9      10     977.966633      False   1.0  0.999880  0.999764  0.999752   \n",
       "10     11     966.663733      False   1.0  0.999886  0.999740  0.999732   \n",
       "11     12     970.894698      False   1.0  0.999881  0.999748  0.999739   \n",
       "12     13     941.204953      False   1.0  0.999879  0.999744  0.999731   \n",
       "13     14    1047.069369      False   1.0  0.999901  0.999738  0.999728   \n",
       "14     15     959.351813      False   1.0  0.999884  0.999722  0.999714   \n",
       "15     16     947.571100      False   1.0  0.999874  0.999741  0.999716   \n",
       "\n",
       "        ev_5      ev_6      ev_7  ...  vamp2_std_2  vamp2_std_3  vamp2_std_4  \\\n",
       "0   0.999609  0.999474  0.998576  ...     0.000117     0.000127     0.000220   \n",
       "1   0.999439  0.999376  0.997497  ...     0.000107     0.000151     0.000238   \n",
       "2   0.999432  0.999371  0.997512  ...     0.000129     0.000144     0.000160   \n",
       "3   0.999448  0.999399  0.997448  ...     0.000150     0.000164     0.000259   \n",
       "4   0.999432  0.999366  0.997466  ...     0.000094     0.000147     0.000248   \n",
       "5   0.999425  0.999358  0.997507  ...     0.000117     0.000158     0.000293   \n",
       "6   0.999429  0.999332  0.997496  ...     0.000151     0.000182     0.000176   \n",
       "7   0.999415  0.999339  0.997499  ...     0.000115     0.000157     0.000239   \n",
       "8   0.999428  0.999353  0.997497  ...     0.000182     0.000174     0.000199   \n",
       "9   0.999428  0.999329  0.997505  ...     0.000133     0.000155     0.000189   \n",
       "10  0.999409  0.999352  0.997459  ...     0.000172     0.000179     0.000277   \n",
       "11  0.999422  0.999331  0.997534  ...     0.000058     0.000144     0.000343   \n",
       "12  0.999449  0.999311  0.997515  ...     0.000084     0.000154     0.000259   \n",
       "13  0.999447  0.999282  0.997532  ...     0.000135     0.000184     0.000253   \n",
       "14  0.999436  0.999322  0.997476  ...     0.000121     0.000151     0.000279   \n",
       "15  0.999439  0.999310  0.997500  ...     0.000085     0.000222     0.000349   \n",
       "\n",
       "    vamp2_std_5  vamp2_std_6  vamp2_std_7  vamp2_std_8  vamp2_std_9  \\\n",
       "0      0.000159     0.000176     0.000176     0.000184     0.000194   \n",
       "1      0.000191     0.000222     0.000230     0.000248     0.000275   \n",
       "2      0.000178     0.000210     0.000220     0.000233     0.000262   \n",
       "3      0.000199     0.000236     0.000237     0.000262     0.000291   \n",
       "4      0.000213     0.000204     0.000212     0.000242     0.000261   \n",
       "5      0.000218     0.000253     0.000267     0.000284     0.000308   \n",
       "6      0.000190     0.000241     0.000249     0.000261     0.000291   \n",
       "7      0.000233     0.000235     0.000246     0.000259     0.000272   \n",
       "8      0.000202     0.000214     0.000220     0.000252     0.000278   \n",
       "9      0.000198     0.000217     0.000217     0.000251     0.000270   \n",
       "10     0.000205     0.000253     0.000262     0.000276     0.000287   \n",
       "11     0.000313     0.000234     0.000236     0.000267     0.000284   \n",
       "12     0.000199     0.000233     0.000236     0.000265     0.000286   \n",
       "13     0.000230     0.000251     0.000260     0.000277     0.000302   \n",
       "14     0.000200     0.000239     0.000243     0.000269     0.000271   \n",
       "15     0.000281     0.000239     0.000242     0.000256     0.000275   \n",
       "\n",
       "    vamp2_std_10  vamp2_std_11  \n",
       "0       0.000201      0.001091  \n",
       "1       0.000299      0.002165  \n",
       "2       0.000268      0.001021  \n",
       "3       0.000313      0.000323  \n",
       "4       0.000261      0.002848  \n",
       "5       0.000309      0.002326  \n",
       "6       0.000310      0.002876  \n",
       "7       0.000285      0.002878  \n",
       "8       0.000288      0.003152  \n",
       "9       0.000284      0.001736  \n",
       "10      0.000287      0.003004  \n",
       "11      0.000297      0.003548  \n",
       "12      0.000309      0.002618  \n",
       "13      0.000322      0.002078  \n",
       "14      0.000284      0.002261  \n",
       "15      0.000284      0.001068  \n",
       "\n",
       "[16 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein = 'abl'\n",
    "key = 'abl-pdb-50ps' # Dataset key \n",
    "study = 'scan_lags' # where the results are saved\n",
    "data_path = Path(f'/home/rzhu/Desktop/projects/kinase_analysis/data') # base dir\n",
    "\n",
    "hps_df = pd.read_csv(data_path/f'{protein}'/'msm'/f'{study}'/'hps.csv')\n",
    "TD = TrajData(protein = protein)\n",
    "TD.add_dataset(rtraj_dir = Path(f'/arc/abl_processed/'), \n",
    "               ftraj_dir= data_path / f'{protein}'/ f'{key}' / 'ftrajs',\n",
    "               dt=0.05,\n",
    "               key=key)\n",
    "study = MSMStudy(hps_table = hps_df,\n",
    "                 traj_data = TD,\n",
    "                 wk_dir = data_path/f'{protein}'/'msm'/f'{study}')\n",
    "study.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set dataset abl-pdb-50ps stride to 1\n",
      "Loading MSM model id 11 from /home/rzhu/Desktop/projects/kinase_analysis/data/abl/msm/scan_lags/11\n",
      "{'hp_id': 11, 'datasets': 'abl-pdb-50ps', 'features': 'dbdist dbdihed achelix aloop', 'dt_out': 0.05, 'time_cutoff': 100, 'tica_lag_time': 1, 'tica_stride': 1000, 'tica_dim': 20, 'tica_kinetic_map': True, 'cluster_n': 1000, 'cluster_stride': 1000, 'cluster_max_iter': 1000, 'seed': 42, 'markov_lag_time': 101, 'markov_count_mode': 'effective', 'markov_count_prior': True, 'msm_mode': 'bayesian'}\n",
      "Loading trajectories...\n",
      "Loading models...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "study.set_hp_id(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free energy surface with microstates \n",
    "plot_fe(traj_all=study.ttraj_cat,\n",
    "        traj_weights = np.concatenate(study.traj_weights, axis=0),\n",
    "        c_centers=study.kmeans_centers[study.connected_states, :],\n",
    "        c_centers_s=20,\n",
    "        d_centers=study.kmeans_centers[study.disconnected_states, :],\n",
    "        d_centers_s=30,\n",
    "        savedir=study.fig_dir/'free_energy.pdf'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timescales \n",
    "plot_ts(timescales=study.baymsm_mod.timescales()[1], \n",
    "        #timescales=study.msm_mod.timescales(),\n",
    "        n_ts = 20, \n",
    "        dt = study.hp_dict.dt_out, \n",
    "        savedir = study.fig_dir/'timescales.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse-grain with PCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.run_pcca(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free energy surface with microstates colored by PCCA states\n",
    "plot_fe(traj_all=study.ttraj_cat,\n",
    "        traj_weights = np.concatenate(study.traj_weights, axis=0),\n",
    "        c_centers=study.kmeans_centers[study.connected_states, :],\n",
    "        c_centers_s=80,\n",
    "        state_assignment=study.pcca_mod.assignments,\n",
    "        n_states=study.pcca_n,\n",
    "        state_population=study.pcca_mod.coarse_grained_stationary_probability,\n",
    "        linewidth=1,\n",
    "        d_centers=study.kmeans_centers[study.disconnected_states, :],\n",
    "        d_centers_s=30,\n",
    "        d_centers_marker='X',\n",
    "        legend_marker_sizes=[200, 200, 200, 200, 200, 200, 200],\n",
    "        savedir = study.fig_dir/'pcca.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I may want to show the crystal structures in the free energy surface\n",
    "# I load the crystals and featurise them here\n",
    "\n",
    "crystal_files = natsorted([str(f) for f in Path(f\"/arc/human_{protein}/\").glob(\"kinoml*.pdb\")])\n",
    "print('Number of crystal structures:', len(crystal_files))\n",
    "\n",
    "frames = [] \n",
    "for crystal in crystal_files:\n",
    "    sample_frame = md.load(crystal)\n",
    "    sample_frame = sample_frame.atom_slice(sample_frame.top.select('mass>1.1'))\n",
    "    frames.append(sample_frame)\n",
    "crystals = md.join(frames)\n",
    "crystals = crystals.superpose(crystals, 0)\n",
    "\n",
    "featurisers = [dbdist_featuriser, dbdihed_featuriser, aloop_featuriser, achelix_featuriser]\n",
    "c_ftrajs_dict = {f.__name__.split('_')[0]:[f(traj=crystals, protein=protein)] for f in featurisers}\n",
    "c_ftrajs, _ = TD.prepare_ftrajs(c_ftrajs_dict, stride=1, frame_no_cutoff=0, convert_dihed_ids=[1])\n",
    "c_ttraj, dtraj, connected_d, c_disconnected_d, c_pcca_assignment = study.transform(c_ftrajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the precomputed Dunbrack states assignment \n",
    "# hdbscan_dist_group / hdbscan_dihed_group -- used hdbscan\n",
    "# distgroup / dihedgroup -- used average-linkage hierachical clustering \n",
    "\n",
    "TD.load_ftrajs(key=key,\n",
    "               feature_names=['hdbscan_dist_group', 'hdbscan_dihed_group'],)\n",
    "distgroup, _ = TD.get_ftrajs(keys=key, \n",
    "                             dt_out=0.05, \n",
    "                             internal_names=['hdbscan_dist_group'], \n",
    "                             time_cutoff=100,\n",
    "                             convert_dihed_ids=None)\n",
    "dihedgroup, _ = TD.get_ftrajs(keys=key, \n",
    "                              dt_out=0.05, \n",
    "                              internal_names=['hdbscan_dihed_group'], \n",
    "                              time_cutoff=100,\n",
    "                              convert_dihed_ids=None)\n",
    "distgroup_cat = np.concatenate(distgroup).flatten()\n",
    "dihedgroup_cat = np.concatenate(dihedgroup).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Dunbrack state compostition for each macrostate\n",
    "# Note - the color scheme haven't been changed yet\n",
    "# They should match the palette used in VMD\n",
    "# I also need to come up with a palette for Dunbrack states \n",
    "\n",
    "dfg_spatial_colors = np.array(['#595959',       # Grey noise\n",
    "                               '#53F4A2',       # Green DFG-in\n",
    "                               '#F54801',       # Red DFG-inter\n",
    "                               '#BA08F4'])      # Purple DFG-out\n",
    "\n",
    "sim_ptraj_cat = np.array([study.micro_to_macro[d] if d in study.connected_states else -1 for d in study.dtraj_cat])\n",
    "\n",
    "for state_i in range(study.pcca_n):\n",
    "    frame_indices = np.where(sim_ptraj_cat == state_i)[0]\n",
    "    spatial_assignments, dihed_assignments = distgroup_cat[frame_indices], dihedgroup_cat[frame_indices]\n",
    "    \n",
    "    spatial_counts, dihed_counts = dunbrack_count(spatial_assignments, dihed_assignments)\n",
    "    plot_dihed_pie(spatial_counts, dihed_counts, \n",
    "                   show_legend=False, show_dihed='no_labels', radius_size=0.35, \n",
    "                   dfg_spatial_colors=dfg_spatial_colors,\n",
    "                   title=f'State {state_i+1}', \n",
    "                   savedir=study.fig_dir/f'state_{state_i+1}_dihed.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse-grained transition matrix and MFPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MFPT matrix\n",
    "\n",
    "mfpt = np.zeros([study.pcca_n, study.pcca_n])\n",
    "mfpt_std = np.zeros([study.pcca_n, study.pcca_n])\n",
    "\n",
    "for i in range(study.pcca_n):\n",
    "    for j in range(study.pcca_n):\n",
    "        mfpt[i,j] = study.baymsm_mod.gather_stats('mfpt', A=study.pcca_mod.sets[i], B=study.pcca_mod.sets[j]).mean\n",
    "        mfpt_std[i,j] = study.baymsm_mod.gather_stats('mfpt', A=study.pcca_mod.sets[i], B=study.pcca_mod.sets[j]).std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFPT matrix\n",
    "plot_mfpt_matrix(mfpt = mfpt,\n",
    "                 mfpt_err = mfpt_std, \n",
    "                 dt = study.hp_dict.dt_out,\n",
    "                 text_f =\".2e\",\n",
    "                 savedir = study.fig_dir/'mfpt_matrix.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFPT graph \n",
    "plot_pcca_graph(traj_all = study.ttraj_cat,\n",
    "                traj_weights = np.concatenate(study.traj_weights, axis=0),\n",
    "                c_centers = study.kmeans_centers[study.connected_states, :],\n",
    "                c_centers_a = 0.5,\n",
    "                c_centers_s = 50,\n",
    "                matrix = mfpt,\n",
    "                pcca_assignment = study.pcca_mod.assignments,\n",
    "                stat_dist = study.msm_mod.stationary_distribution,\n",
    "                savedir = study.fig_dir/'mfpt_graph.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 eigenvectors \n",
    "# The max and min are shown in red and blue respectively\n",
    "for ev_id in range(10):\n",
    "    plot_ev(ev = study.msm_mod.eigenvectors_right()[:,ev_id+1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ],\n",
    "            c_centers = study.kmeans_centers[study.connected_states,:],\n",
    "            traj_all = study.ttraj_cat,\n",
    "            traj_weights = np.concatenate(study.traj_weights,axis=0),\n",
    "            title = f'eigenvector_{ev_id+2}',\n",
    "            savedir = study.fig_dir/f'eigenvector_{ev_id+2}.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from each macrostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from each macrostate \n",
    "n_sample = 100\n",
    "for pcca_state in range(study.pcca_n):\n",
    "    samples = study.sample_from_macrostate(n_sample = n_sample,\n",
    "                                           macrostate_id = pcca_state,\n",
    "                                           ci_cutoff = 0.8,\n",
    "                                           weights ='equilibrium')  # weights based on stationary distribution\n",
    "    study.save_samples(samples, \n",
    "                       fname = study.sample_dir/f'macrostate_{pcca_state}_{n_sample}_samples.pdb',\n",
    "                       save_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = study.sample_from_macrostate(n_sample = 10,\n",
    "                                        macrostate_id = 3,\n",
    "                                        ci_cutoff = 0.8,\n",
    "                                        weights ='equilibrium')  # weights based on stationary distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Josh's writhe analysis\n",
    "# I retrieve the transition matrix and the sub-matrix for the samples \n",
    "# This cell is irrelevant for the analysis\n",
    "\n",
    "import json\n",
    "\n",
    "np.save(study.sample_dir/'tmax.npy', study.msm_mod.transition_matrix)\n",
    "\n",
    "dtrajs = []\n",
    "for s_files in list(study.sample_dir.rglob('macrostate_*_samples.json')):\n",
    "    samples = json.load(open(s_files, 'r'))\n",
    "    for ftraj_id, frame_ids in samples.items():\n",
    "        for frame_id in frame_ids:\n",
    "            dtrajs.append(study.dtrajs[int(ftraj_id)][int(frame_id)])\n",
    "\n",
    "sub_transition_matrix = study.msm_mod.transition_matrix[np.ix_(dtrajs, dtrajs)]\n",
    "np.save(study.sample_dir/'sample_tmax.npy', sub_transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample core microstates for PCCA+ macrostates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each macrostate, I sample n_sample=100 structures from the microstates \n",
    "# that have the top k=3 membership probabilities\n",
    "\n",
    "n_sample = 100\n",
    "k=3\n",
    "\n",
    "for pcca_state in range(study.pcca_n):\n",
    "    microstate_indices = np.argsort(study.pcca_mod.memberships[:,pcca_state])[-k:]\n",
    "    distrib = np.zeros(len(study.connected_states))\n",
    "    distrib[microstate_indices] = 1/k\n",
    "\n",
    "    samples = study.sample_from_distrib(n_sample, distrib)\n",
    "    study.save_samples(samples, \n",
    "                       fname = study.sample_dir/f'macrostate_{pcca_state}_core_{n_sample}_samples.pdb',\n",
    "                       save_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample core microstates for slow processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the slowest n=2 processes (eigenvectors), I sample n_sample=100 structures from\n",
    "# the microstates whose eigenvector components \n",
    "# lie at the highest-k-positive and highest-k-negative extremes of each process\n",
    "\n",
    "n=2\n",
    "n_sample=100\n",
    "k=2\n",
    "\n",
    "for ev_id in range(2):\n",
    "    ev = study.msm_mod.eigenvectors_right()[:,ev_id+1]\n",
    "    ev_pos_indices = np.argsort(ev)[-k:]\n",
    "    ev_neg_indices = np.argsort(ev)[:k]\n",
    "\n",
    "    distrib = np.zeros(len(study.connected_states))\n",
    "    distrib[ev_pos_indices] = 1/k\n",
    "    samples = study.sample_from_distrib(n_sample, distrib)\n",
    "    study.save_samples(samples, \n",
    "                       fname = study.sample_dir/f'process_{ev_id+1}_core_positive_{n_sample}_samples.pdb',\n",
    "                       save_ids=True)\n",
    "    \n",
    "    distrib = np.zeros(len(study.connected_states))\n",
    "    distrib[ev_neg_indices] = 1/k\n",
    "    samples = study.sample_from_distrib(n_sample, distrib)\n",
    "    study.save_samples(samples, \n",
    "                       fname = study.sample_dir/f'process_{ev_id+1}_core_negative_{n_sample}_samples.pdb',\n",
    "                       save_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The highest flux pathways and the bottleneck states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  10  11  13  15  16  18  25  26  27  29  31  34  40  41  42  44  46\n",
      "  47  49  52  54  55  56  58  60  62  63  69  70  79  80  84  85  87  90\n",
      "  92  93  94  96  98 100 102 108 110 111 112 113 117 120 122 125 128 131\n",
      " 132 133 135 136 137 138 144 148 150 151 154 155 156 158 162 164 166 169\n",
      " 170 175 176 177 180 182 184 189 191 193 195 196 197 202 204 205 206 209\n",
      " 211 215 217 218 221 222 224 229 234 236 238 246 251 252 254 255 256 258\n",
      " 259 260 261 262 264 269 271 274 279 280 282 285 289 298 303 304 305 310\n",
      " 311 312 313 314 317 318 322 325 328 330 333 335 337 338 339 344 345 346\n",
      " 347 351 355 356 359 362 363 365 367 368 369 373 379 386 387 388 389 391\n",
      " 393 394 396 398 399 401 404 406 408 412 413 417 419 423 425 426 429 430\n",
      " 431 435 441 443 445 449 454 457 460 461 463 464 467 468 474 476 477 478\n",
      " 479 480 486 487 493 494 495 497 500 501 502 506 508 513 518 520 522 524\n",
      " 525 526 527 528 533 535 540 541 544 545 550 553 554 555 559 560 564 565\n",
      " 570 575 576 577 578 580 581 582 583 590 593 596 603 605 613 614 616 617\n",
      " 618 621 622 630 633 635 638 640 641 643 644 646 647 648 654 656 657 660\n",
      " 661 662 665 668 669 672 676 678 681 688 690 691 692 693 695 702 704 710\n",
      " 712 715 716 717 719 727 728 729 730 736 737 738 740 742 751 752 753 759\n",
      " 760 761 763 766 768 780 781 787 790 791 792 796 798 799 802 806 810 811\n",
      " 814 820 823 824 825 826 827 831 832 834 838 839 844 845 846 848 850 851\n",
      " 852 853 855 857 867 869 870 872 875 876 879 884 887 890 893 894 895 897\n",
      " 900 901 903 906 910 911 912 914 915 917 918 920 921 924 928 929 930 932\n",
      " 936 937 940 941 948 950 953 957 960 961 967 970 971 974 976 978 980 982\n",
      " 985 986 989 990 991 993 996 998 999] [  2  33  39  51  59  61  66  72  76  78  88  95 101 106 129 134 145 181\n",
      " 187 208 214 220 225 249 263 278 281 284 290 301 307 315 323 334 342 352\n",
      " 375 376 378 381 385 402 427 433 436 448 455 456 458 459 484 499 510 515\n",
      " 521 531 532 536 547 563 572 595 624 625 631 634 636 652 670 674 679 686\n",
      " 689 713 722 745 747 755 769 777 800 812 854 862 865 878 882 898 902 922\n",
      " 939 942 956 987]\n"
     ]
    }
   ],
   "source": [
    "# I find the macrostates that are most likely to be the active and inactive states\n",
    "# according to the FES and Dunbrack state decomposition\n",
    "# I use a confidence of 0.95 to filter out the some microstates. The value can be adjusted\n",
    "\n",
    "inactive_ms_id = 5\n",
    "active_ms_id = 4\n",
    "\n",
    "start_state_ids = np.where(study.pcca_mod.memberships[:,inactive_ms_id] > 0.95)[0]\n",
    "end_state_ids = np.where(study.pcca_mod.memberships[:,active_ms_id] > 0.95)[0]\n",
    "print(start_state_ids, end_state_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rzhu/Loc/miniconda3/envs/msm/lib/python3.10/site-packages/deeptime/markov/tools/flux/pathways.py:294: RuntimeWarning: Maximum number of iterations reached\n",
      "  warnings.warn(\"Maximum number of iterations reached\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Compute the tpt pathways \n",
    "tpt_activation = study.msm_mod.reactive_flux(start_state_ids, end_state_ids)\n",
    "paths, pathfluxes = tpt_activation.pathways(fraction=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the pathway with the highest flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States in the highest flux pathway: [791 714 515]\n"
     ]
    }
   ],
   "source": [
    "max_flux_index = np.argmax(pathfluxes)\n",
    "highest_flux_pathway = paths[max_flux_index]\n",
    "highest_flux_value = pathfluxes[max_flux_index]\n",
    "print('States in the highest flux pathway:', highest_flux_pathway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the minimum flux transition (the bottleneck states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the bottleneck state: 0\n"
     ]
    }
   ],
   "source": [
    "path_fluxes = [tpt_activation.net_flux[highest_flux_pathway[i], highest_flux_pathway[i+1]]\n",
    "               for i in range(len(highest_flux_pathway) - 1)]\n",
    "bottleneck_index = np.argmin(path_fluxes)\n",
    "bottleneck_state = highest_flux_pathway[bottleneck_index]\n",
    "bottleneck_flux_value = path_fluxes[bottleneck_index]\n",
    "print('Index of the bottleneck state:', bottleneck_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Dunbrack state decomposition for states along the highest flux pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('binary')\n",
    "colors = cmap(np.linspace(0, 1, len(highest_flux_pathway)))\n",
    "\n",
    "plot_fe(traj_all = study.ttraj_cat,\n",
    "        traj_weights = np.concatenate(study.traj_weights, axis=0),\n",
    "        c_centers = study.kmeans_centers[highest_flux_pathway, :],\n",
    "        c_centers_c = colors,\n",
    "        c_centers_marker = 'o',\n",
    "        c_centers_a = 1,\n",
    "        c_centers_s = 50,\n",
    "        linewidth = 1,\n",
    "        title = f'Highest flux pathway (flux = {highest_flux_value:.2e})',\n",
    "        savedir= study.fig_dir/'highest_flux_path.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign transition states to Dunbrack states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_states = compute_index_states(study.dtrajs)\n",
    "snapshot_ids = [index_states[state] for state in highest_flux_pathway]\n",
    "state_dihedgroup_counts = []\n",
    "for i in range(len(highest_flux_pathway)):\n",
    "    assignment = np.concatenate([dihedgroup[id[0]][id[1]] for id in snapshot_ids[i]])\n",
    "    counts = [np.count_nonzero([assignment == i]) for i in range(-1, 8)]\n",
    "    state_dihedgroup_counts.append(counts)\n",
    "dihedgroup_state_counts = np.array(state_dihedgroup_counts).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again I will need to update the color scheme \n",
    "\n",
    "x = list(range(len(highest_flux_pathway)))\n",
    "dihed_colors = np.array([\n",
    "                    (128/255, 128/255, 128/255),   # Gray\n",
    "                    (235/255, 95/255, 70/255),     # Light Red\n",
    "                    (240/255, 146/255, 58/255),    # Flamebright\n",
    "                    (255/255, 214/255, 92/255),    # Light yellow\n",
    "                    (255/255, 188/255, 214/255),   # Light pink\n",
    "                    (210/255, 180/255, 140/255),   # Tan\n",
    "                    (196/255, 79/255, 108/255),    # Strawberry\n",
    "                    (25/255, 189/255, 85/255),     # Light Green\n",
    "                    (136/255, 75/255, 204/255)])   # Light Purple\n",
    "labels = ['noise', 'BLAminus', 'BLAplus', 'ABAminus', 'BLBminus', 'BLBplus', 'BLBtrans', 'BABtrans', 'BBAminus']\n",
    "\n",
    "width = 0.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(len(highest_flux_pathway))\n",
    "y = 0\n",
    "\n",
    "for group_name, group_count, color in zip(labels, dihedgroup_state_counts, dihed_colors):\n",
    "    p = ax.bar(x, group_count, width, label=group_name, bottom=bottom, color=color)\n",
    "    y += p[bottleneck_index].get_height()\n",
    "    bottom += group_count\n",
    "print(y)\n",
    "x = p[bottleneck_index].get_x() + p[bottleneck_index].get_width() / 2\n",
    "ax.text(x, y*0.9, '*', ha='center', va='bottom', fontsize=25, color='k')\n",
    "ax.annotate(\"Bottleneck\", (x, y), xytext=(x, y*1.2),\n",
    "            ha='center', color='k', fontsize=12)\n",
    "\n",
    "ax.set_yticks([0, 20000, 40000, 60000, 80000])\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Highest flux pathway state')\n",
    "ax.legend(loc=\"upper left\", fontsize=10)\n",
    "\n",
    "plt.savefig(study.fig_dir/'highest_flux_pathway_bottleneck_state.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample n_sample structures from microstates along the highest-flux pathway "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling trajectory /arc/abl_processed/run47-clone7.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rzhu/Loc/miniconda3/envs/msm/lib/python3.10/site-packages/mdtraj/core/trajectory.py:441: UserWarning: top= kwargs ignored since this file parser does not support it\n",
      "  warnings.warn(\"top= kwargs ignored since this file parser does not support it\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling trajectory /arc/abl_processed/run47-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run47-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run47-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run2-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run47-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run64-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run30-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run2-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run61-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run81-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run64-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run38-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run27-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run27-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run31-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run73-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run80-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run31-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run30-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run46-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run77-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run2-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run39-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run72-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run78-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run24-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run80-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run17-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run2-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run64-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run46-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run31-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run39-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run24-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run27-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run34-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run31-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run50-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run27-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run31-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run61-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run64-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run24-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run35-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run78-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run75-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run27-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run2-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run50-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run38-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run35-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run35-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run80-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run72-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run61-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run71-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run65-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run72-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run65-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run21-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run65-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run24-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run34-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run50-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run60-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run61-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run72-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run50-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run35-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run21-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run75-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run56-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run58-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run58-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run58-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run58-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run52-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run52-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run52-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run52-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run52-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run43-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run44-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run42-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run13-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run42-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run43-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run54-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run44-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run32-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run11-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run44-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run42-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run49-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run37-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run44-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run69-clone7.h5\n",
      "Sampling trajectory /arc/abl_processed/run54-clone6.h5\n",
      "Sampling trajectory /arc/abl_processed/run37-clone8.h5\n",
      "Sampling trajectory /arc/abl_processed/run54-clone5.h5\n",
      "Sampling trajectory /arc/abl_processed/run49-clone9.h5\n",
      "Sampling trajectory /arc/abl_processed/run11-clone9.h5\n"
     ]
    }
   ],
   "source": [
    "n_sample = 1000\n",
    "for i, state_id in enumerate(highest_flux_pathway):\n",
    "    samples = study.sample_from_microstate(n_sample=n_sample, microstate_id=state_id)\n",
    "    if i == bottleneck_index:\n",
    "        study.save_samples(samples, \n",
    "                           fname = study.sample_dir/f'samples_bottleneck',\n",
    "                           save_ids=True,\n",
    "                           concat=False)\n",
    "    elif i == bottleneck_index + 1:\n",
    "        study.save_samples(samples, \n",
    "                           fname = study.sample_dir/f'post_bottleneck_state',\n",
    "                           save_ids=True,\n",
    "                           concat=False)\n",
    "    else:\n",
    "        study.save_samples(samples, \n",
    "                           fname = study.sample_dir/f'pathway_state_index_{i}',\n",
    "                           save_ids=True,\n",
    "                           concat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot DFG dihedrals along pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD.load_ftrajs(key=key,\n",
    "               feature_names=['dbdist', 'dbdihed'],)\n",
    "dbdist, _ = TD.get_ftrajs(keys=key, \n",
    "                          dt_out=0.05, \n",
    "                          internal_names=['dbdist'], \n",
    "                          time_cutoff=100,\n",
    "                          convert_dihed_ids=None)\n",
    "dbdihed, _ = TD.get_ftrajs(keys=key, \n",
    "                           dt_out=0.05, \n",
    "                           internal_names=['dbdihed'], \n",
    "                           time_cutoff=100,\n",
    "                           convert_dihed_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dihedral cluster centroids for reference\n",
    "# I will need to use the hdbscan centroids instead \n",
    "\n",
    "dihed_centroids_f = data_path / f'{protein}' / 'clustering' / 'dfg_dihed_centroids.npy'\n",
    "dihed_centroids = np.load(dihed_centroids_f, allow_pickle=True).item()\n",
    "dihed_centroids = np.concatenate([dihed_centroids['dfg-in'], dihed_centroids['dfg-inter'], dihed_centroids['dfg-out']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spatial cluster centroids for reference\n",
    "# Again use hdbscan \n",
    "\n",
    "spatial_centroids_f = data_path / f'{protein}' / 'clustering' / 'dfg_spatial_centroids.npy'\n",
    "spatial_centroids = np.load(spatial_centroids_f, allow_pickle=True)\n",
    "\n",
    "spatial_colors = np.array([\n",
    "(173/255, 35/255, 10/255),   # Red\n",
    "(28/225, 128/255, 65/255),   # Green\n",
    "(80/255, 29/255, 138/255)])  # Purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_states = compute_index_states(study.dtrajs)\n",
    "\n",
    "nrows = len(highest_flux_pathway)\n",
    "ncols = 5\n",
    "ax_size = 0.15\n",
    "\n",
    "fig = plt.figure(figsize=(14, 14))\n",
    "axes = []\n",
    "\n",
    "# Create axes and set ticks and ticklabels \n",
    "for i in range(nrows):\n",
    "    new_row_axes = []\n",
    "    new_row_axes.append(fig.add_axes([0.10,           1-(i+1)*ax_size, ax_size, ax_size]))\n",
    "    new_row_axes.append(fig.add_axes([0.18+ax_size,   1-(i+1)*ax_size, ax_size, ax_size]))\n",
    "    new_row_axes.append(fig.add_axes([0.18+2*ax_size, 1-(i+1)*ax_size, ax_size, ax_size]))\n",
    "    new_row_axes.append(fig.add_axes([0.18+3*ax_size, 1-(i+1)*ax_size, ax_size, ax_size]))\n",
    "    new_row_axes.append(fig.add_axes([0.26+4*ax_size, 1-(i+1)*ax_size, ax_size, ax_size]))\n",
    "    \n",
    "    for ax in new_row_axes:\n",
    "        ax.tick_params(left=False, bottom=False, labelbottom=False, labelleft=False)\n",
    "    new_row_axes[0].tick_params(left=True, bottom=False, labelbottom=False, labelleft=True)\n",
    "    new_row_axes[1].tick_params(left=True, bottom=False, labelbottom=False, labelleft=True)\n",
    "    new_row_axes[-1].tick_params(left=True, bottom=False, labelbottom=False, labelleft=True)\n",
    "\n",
    "    axes.append(new_row_axes)\n",
    "\n",
    "axes[-1][0].tick_params(left=True,  bottom=True, labelbottom=True, labelleft=True)\n",
    "axes[-1][1].tick_params(left=True,  bottom=True, labelbottom=True, labelleft=True)\n",
    "axes[-1][2].tick_params(left=False, bottom=True, labelbottom=True, labelleft=False)\n",
    "axes[-1][3].tick_params(left=False, bottom=True, labelbottom=True, labelleft=False)\n",
    "axes[-1][4].tick_params(left=True,  bottom=True, labelbottom=True, labelleft=True)\n",
    "\n",
    "# Plot data by row \n",
    "for i in range(nrows):\n",
    "    snapshot_ids = index_states[highest_flux_pathway[i]]\n",
    "    distances = np.array([dbdist[id[0]][id[1]] for id in snapshot_ids])\n",
    "    # axes[i][0].scatter(distances[:,0], distances[:,1], s=1)\n",
    "    sns.kdeplot(x=distances[:,0], y=distances[:,1], ax=axes[i][0], levels=5, zorder=1)\n",
    "    axes[i][0].scatter(spatial_centroids[:,0], spatial_centroids[:,1], color=spatial_colors, marker='X', s=40, zorder=2)\n",
    "    axes[i][0].set_xlim([0.0, 2.2])\n",
    "    axes[i][0].set_ylim([0.0, 2.2])\n",
    "    axes[i][0].set_ylabel('d2 (nm)')\n",
    "    axes[i][0].set_yticks([0.75, 1.5])\n",
    "    axes[i][0].set_xticks([0.75, 1.5])\n",
    "    if i == nrows-1: axes[i][0].set_xlabel('d1 (nm)')\n",
    "    axes[i][0].grid(color='gray', linestyle=':', alpha=0.7)\n",
    "\n",
    "    dihedrals = np.array([dbdihed[id[0]][id[1]] for id in snapshot_ids])\n",
    "    # axes[i][1].scatter(dihedrals[:,0], dihedrals[:,1], s=1)\n",
    "    # axes[i][2].scatter(dihedrals[:,2], dihedrals[:,3], s=1)\n",
    "    # axes[i][3].scatter(dihedrals[:,4], dihedrals[:,5], s=1)\n",
    "    sns.kdeplot(x=dihedrals[:,0], y=dihedrals[:,1], ax=axes[i][1], levels=5, zorder=1)\n",
    "    sns.kdeplot(x=dihedrals[:,2], y=dihedrals[:,3], ax=axes[i][2], levels=5, zorder=1)\n",
    "    sns.kdeplot(x=dihedrals[:,4], y=dihedrals[:,5], ax=axes[i][3], levels=5, zorder=1)\n",
    "    axes[i][1].scatter(dihed_centroids[:,0], dihed_centroids[:,1], color=dihed_colors[1:], marker='X', s=35, zorder=2)\n",
    "    axes[i][2].scatter(dihed_centroids[:,2], dihed_centroids[:,3], color=dihed_colors[1:], marker='X', s=35, zorder=2)\n",
    "    axes[i][3].scatter(dihed_centroids[:,4], dihed_centroids[:,5], color=dihed_colors[1:], marker='X', s=35, zorder=2)\n",
    "\n",
    "    for ax in axes[i][1:4]:\n",
    "        ax.set_xlim([-np.pi, np.pi])\n",
    "        ax.set_ylim([-np.pi, np.pi])\n",
    "        ax.set_xticks([-np.pi/2, 0, np.pi/2])\n",
    "        ax.set_yticks([-np.pi/2, 0, np.pi/2])\n",
    "        ax.set_xticklabels([r'-$\\pi$/2', '0', r'$\\pi$/2'])\n",
    "        ax.set_yticklabels([r'-$\\pi$/2', '0', r'$\\pi$/2'])\n",
    "        if i==nrows-1: \n",
    "            ax.set_xlabel('Phi')\n",
    "        ax.grid(color='gray', linestyle=':', alpha=0.7)\n",
    "\n",
    "    axes[i][1].set_ylabel('Psi')\n",
    "    if i == 0: \n",
    "        axes[i][1].set_title('X-DFG')\n",
    "        axes[i][2].set_title('DFG-D')\n",
    "        axes[i][3].set_title('DFG-F')\n",
    "\n",
    "    axes[i][4].hist(dihedrals[:,8], bins=36)\n",
    "    for j in range(dihed_centroids.shape[1]):\n",
    "        axes[i][4].axvline(x=dihed_centroids[j,6], ymin=ax.get_ylim()[0], ymax=ax.get_ylim()[1], \n",
    "                           color=dihed_colors[1:][j], alpha=0.9, linestyle='--', linewidth=2, zorder=2)\n",
    "    axes[i][4].set_xlim([-np.pi, np.pi])\n",
    "    if i == nrows-1: \n",
    "        axes[i][4].set_xlabel('Chi1')\n",
    "        axes[i][4].set_xticks([-np.pi/2, 0, np.pi/2])\n",
    "        axes[i][4].set_xticklabels([r'-$\\pi$/2', '0', r'$\\pi$/2'])\n",
    "    if i == 0: axes[i][4].set_title('DFG-F')\n",
    "\n",
    "plt.savefig(study.fig_dir/'highest_flux_pathway_dfg_feature_shift.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
